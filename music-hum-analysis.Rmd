---
title: "What Factors Make a Masterpiece?"
author: "Noah Love"
date: "8/16/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(spotifyr)
library(tidyverse)
library(knitr)
library(lubridate)
library(tidyverse)
library(corrplot)
library(ggridges)

```


```{r message=FALSE, warning=FALSE, include=FALSE}
my_id <- ''

Sys.setenv(SPOTIFY_CLIENT_ID = '')
Sys.setenv(SPOTIFY_CLIENT_SECRET = '')

access_token <- get_spotify_access_token()
```

## Introduction
Throughout our semester in Masterpieces of Western Music, we studied a variety of pieces and composers, and yet haven't arrived at a definitive set of characteristics that compose an individual masterpiece. Further, we compiled our own personal favorite songs, a playlist fit for if Manhattan was set adrift into the ocean and Columbia students alone chose the music we must survive on. 

### Spotify Data Analysis 
Spotify music provides an incredible API that has a wealth of information related to each and every song in their repository. Spotify themselves do the hard work of data processing individual characteristics like time signature and qualitative descriptors like loudness, instrumentalness or acousticness. There are broadly speaking 3 categories of factors:

- Mood: Danceability, Valence, Energy, Tempo
- Properties: Loudness, Speechiness, Instrumentalness
- Context: Liveness, Acousticness

Valence is a particularly fun and relavent feature for our class. Valence is musical positiveness conveyed by a track. Tracks with high valence sound more positive (happy, cheerful, euphoric), while tracks with low valence sound more negative (sad, depressed, angry). In a sense, Spotify is trying to deduce the affect of the song mathematically and giving that affect a number and continuum to exist on. 

However, these characteristics aren't always as black and white as they mean seem. Having a number between 0 and 1 for each characteristic seems definitive, and yet they are not obvious. One inherent problem with larger works is the difficulty have having one number, an average, describe an entire movement. 

For example, we can look at Hector Berlioz's Symphonie Fantastique

```{r echo=FALSE, message=FALSE, warning=FALSE}
joy <- get_artist_audio_features('Hector Berlioz')

berlioz <- joy %>% 
  filter(album_release_date == "2021-07-23")

berlioz %>% 
    select(.data$track_name, .data$valence, danceability, loudness, liveness, energy, tempo) %>% 
    head(5) %>% 
    kable()

```
The fourth movement, a quick and almost chaotic at times march is described by spotify as without liveness. At the same time, it is listed as more dancable than the second movement, a ball. It shows some of the shortcomings of specific and narrow analytics broadly applied to something as varied as music. Especially when the tracks are long and varied like syphonic works, it seems that the number will be muddled by the different pieces. 

In our scenario, the easiest way to pull the characteristics is to use the individual playlist identifiers. If this analysis wishes to be repeated, the playlists should be publicly availabe:

- Columbia's desert playlist: 63HV8Y11tj4Yq8vj8TYpLm
- Our masterpieces: 46l09Vietu0U65GEyyWH1g

They can be easily called using:

```{r}
desert_island <- get_playlist(
    playlist_id = "63HV8Y11tj4Yq8vj8TYpLm",
    authorization = access_token
)
```

```{r include=FALSE}
tracks <- desert_island$tracks
```

```{r find track ids, echo=FALSE, message=FALSE, warning=FALSE, include=FALSE}
larger_frame <- desert_island[13]

test <- larger_frame[1]$tracks

df <- test$items

tracks <- df$track.id

tracksMatrix <- as.matrix(tracks)
```

```{r get song information, message=FALSE, warning=FALSE, include=FALSE}
more_info_list <- larger_frame$tracks

more_info <- as_tibble(more_info_list$items)

larger_frame_important <- more_info %>% 
    select(track.id, track.artists, track.duration_ms, track.explicit, track.name, track.album.name, track.album.release_date, track.popularity)

```



```{r message=FALSE, warning=FALSE, include=FALSE}

track_features <- get_track_audio_features("7t86fVeDAd63ThaR0ZkxXS")
#track_features2 <- get_track_audio_analysis("79MMMdYL00iwKVHBSAUkLY")

i <- 0
datalist  <- list()

for(i in 1:length(tracks)){
    track_individuals <- get_track_audio_features(tracks[i])
    
    track_individuals$i #which iteration
    
    datalist[[i]] <- track_individuals
}

spotify_data_half <- do.call(rbind, datalist)
```

```{r include=FALSE}

# rename the song characteristics column to match larger set
spotify_data_half <- spotify_data_half %>% 
    relocate(id) %>% 
    dplyr::rename(track.id = id)
```

```{r include=FALSE}
#merge the two smaller sets
spotify_data <- full_join(spotify_data_half, larger_frame_important, by = "track.id")

```



```{r make artists tibble desert, message=FALSE, warning=FALSE, include=FALSE}
# initialize artists column
spotify_data <- spotify_data %>% 
     add_column(artists = "NAME")

i <- 0
#convert artist embedded data table into only first artist char
for(i in 1:length(spotify_data$track.artists)){
    
    # create tibble of artist and song id
    single_artist <- as.data.frame(spotify_data$track.artists[i])
    single_artist <- as.tibble(single_artist)
    
    single_artist_name <- single_artist$name

    spotify_data$artists[i] <- single_artist_name
}

```

```{r add artists in and clean data frame, include=FALSE}
spotify_data <- spotify_data %>% 
    select(-type, -uri, -track_href, -analysis_url, -track.artists) %>% 
    relocate(track.name)
    
head(spotify_data)

glimpse(spotify_data)
```

First, some simple exploration of our choices to fill our desert island with sound. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
# https://www.kaggle.com/cihanoklap/top-songs-on-spotify-what-makes-them-popular
top_artists <- spotify_data %>%
    group_by(artists)  %>%
    dplyr::summarise(n_apperance = n()) %>%
    filter(n_apperance > 3) %>%
    arrange(desc(n_apperance))

top_artists$artists <- factor(top_artists$artists, levels = top_artists$artists[order(top_artists$n_apperance)]) # in order to visualise the list in descending order 

ggplot(top_artists, aes(x = artists, y = n_apperance)) +
    geom_bar(stat = "identity",  fill = "tomato2", width = 0.6 ) + 
    labs(title = "Top artists on our desert island", x = "Artists", y = "Number of apperances on the desert playlist") +
    theme(plot.title = element_text(size=15,hjust=-.3,face = "bold"), axis.title = element_text(size=12)) +
    geom_text(aes(label=n_apperance), hjust = 2, size = 3, color = 'white') +
    coord_flip()
```


Although some of this is related to people submitting multiple, of the 132 songs, there is a wide variety of artists in the most frequent songs. Classics, jazz, and pop all populate our most selected pieces. The recording times also vary widly, ranging from 1961 to june of this year, although as a whole the median is decently close to present. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
spotify_data$track.album.release_date <- as.Date(spotify_data$track.album.release_date)

summary(spotify_data$track.album.release_date)
```

Through the use of spotify's descriptors, we are able to look at how they interact together. Using a correlation plot on our desert island dataset, it appears very few things are closely related. 

```{r echo=FALSE, message=FALSE, warning=FALSE}

spotify_data_num <- spotify_data[,-c((1:2),(17:19),(21))] 

mtCor <- cor(spotify_data_num)
corrplot(mtCor, method = "ellipse", type = "upper", tl.srt = 45)

```

Energy and loudness is strongly correlated. Acousticness and instrumentalness are strongly negatively correlated with energy and loudness. This seems reasonable as there is very infrequently really loud instrumental or acappella songs. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
spotify_data %>% 
  arrange(-acousticness) %>% 
  select(track.name, acousticness) %>% 
  head(4) %>% 
  kable() 
  
```
Particularly pulled out in this "acousticness" are piano pieces. At the top is Debussy in a rather slow and tender Prelude. 

Interestingly, popularity (to all spotify listeners) is not very correlated with anything except loudness, and negatively to acousticness. It appears we like large, grand sounds. In fact, the majority of our playlist skews towards loudness. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
# https://www.kaggle.com/cihanoklap/top-songs-on-spotify-what-makes-them-popular

loudness_density <- ggplot(spotify_data) +
    geom_density(aes(loudness, fill ="loudness")) + 
    scale_x_continuous(name = "Loudness") +
    scale_y_continuous(name = "Density") +
    ggtitle("Density plot of Loudness") +
    theme_bw() +
    theme(plot.title = element_text(size = 14, face = "bold"),
            text = element_text(size = 12)) +
    theme(legend.title=element_blank()) +
    scale_fill_brewer(palette="Paired")

print(loudness_density)
```


However, popularity and loudness are innevitably skewed towards more modern songs that have a larger listening audience. This is indeed true even for our playlist, as the top four songs for popularity have come out in the last four years.

```{r echo=FALSE, message=FALSE, warning=FALSE}
spotify_data %>% 
  arrange(-track.popularity) %>% 
  select(track.name, track.popularity, artists, track.album.release_date) %>% 
  head(4) %>% 
  kable() 


```

Although I am not able to personally derive meaning from the distribution of keys, I found it interest gradual choice and wide variety of keys. 

```{r echo=FALSE, message=FALSE, warning=FALSE}

# https://www.kaggle.com/cihanoklap/top-songs-on-spotify-what-makes-them-popular

spotify_data$key <- as.character(spotify_data$key)
spotify_data$key <- plyr::revalue(spotify_data$key, c("0" = "C", "1" = "C♯,D♭", "2" = "D", "3" = "D♯,E♭", "4" = "E", "5" =  "F", "6" = "F♯,G♭","7" = "G","8" = "G♯,A♭","9" = "A","10" = "A♯,B♭","11" = "B"))

song_keys <- spotify_data %>%
    dplyr::group_by(key) %>%
    dplyr::summarise(n_key = n()) %>%
    arrange(desc(n_key))

song_keys$key <- factor(song_keys$key, levels = song_keys$key[order(song_keys$n_key)]) # in order to visualise the keys in descending order

ggplot(song_keys, aes(x = reorder(key,-n_key), y = n_key, fill = reorder(key,-n_key))) +
    geom_bar(stat = "identity") +
    labs(title = "Distribution of the Keys of Top Songs", x = "Keys", y = "Count of Keys on the Top 100") +
    geom_text(aes(label=n_key), position = position_stack(vjust = 0.8)) +
    theme_bw() +
    theme(plot.title = element_text(size=15,face = "bold"), axis.title = element_text(size=12)) +
    theme(legend.position="none")
```

Over our desert island playlist, there is a suprising amount of normality to be seen within our 132 samples. Danceability, energy and valence all form rather normal curves and it appears that there is a good zone for making a piece that Columbia students like. That, or maybe we can even extrapolate that we are relatively normal (and don't all listen to hard metal or something at the extreme). 

```{r echo=FALSE, message=FALSE, warning=FALSE}

# https://www.kaggle.com/cihanoklap/top-songs-on-spotify-what-makes-them-popular
correlated_density <- ggplot(spotify_data) +
    geom_density(aes(energy, fill ="energy", alpha = 0.1)) + 
    geom_density(aes(valence, fill ="valence", alpha = 0.1)) + 
    geom_density(aes(danceability, fill ="danceability", alpha = 0.1)) + 
    scale_x_continuous(name = "Energy, Valence and Danceability") +
    scale_y_continuous(name = "Density") +
    ggtitle("Density plot of Energy, Valence and Danceability") +
    theme_bw() +
    theme(plot.title = element_text(size = 14, face = "bold"),
          text = element_text(size = 12)) +
    theme(legend.title=element_blank()) +
    scale_fill_brewer(palette="Accent")

correlated_density
```



## What makes a masterpiece

```{r echo=FALSE, message=FALSE, warning=FALSE}
masterpieces <- get_playlist(
    playlist_id = "46l09Vietu0U65GEyyWH1g",
    authorization = access_token
)

tracks_masterpieces <- masterpieces$tracks

larger_frame_masterpieces <- masterpieces[13]
test_masterpieces <- larger_frame_masterpieces[1]$tracks
df_masterpieces <- test_masterpieces$items

tracks_masterpieces <- df_masterpieces$track.id

tracksMatrix_masterpieces <- as.matrix(tracks_masterpieces)

more_info_list_masterpieces <- larger_frame_masterpieces$tracks

more_info_masterpieces <- as_tibble(more_info_list_masterpieces$items)

larger_frame_important_masterpieces <- more_info_masterpieces %>% 
    select(track.id, track.artists, track.duration_ms, track.explicit, track.name, track.album.name, track.album.release_date, track.popularity)

```



```{r echo=FALSE, message=FALSE, warning=FALSE}
track_features_masterpieces <- get_track_audio_features("4yg4OeZxDSqyXx6NUxtxHR")

i <- 0
datalist_masterpieces  <- list()

for(i in 1:length(tracks_masterpieces)){
    track_individuals_masterpieces <- get_track_audio_features(tracks_masterpieces[i])
    
    track_individuals_masterpieces$i #which iteration
    
    datalist_masterpieces[[i]] <- track_individuals_masterpieces
}

spotify_data_half_masterpieces <- do.call(rbind, datalist_masterpieces)


# rename the song characteristics column to match larger set
spotify_data_half_masterpieces <- spotify_data_half_masterpieces %>% 
    relocate(id) %>% 
    dplyr::rename(track.id = id)

#merge the two smaller sets
spotify_data_masterpieces <- full_join(spotify_data_half_masterpieces, larger_frame_important_masterpieces, by = "track.id")

```


```{r make artists tibble masterpieces, echo=FALSE, message=FALSE, warning=FALSE}
# initialize artists column
spotify_data_masterpieces <- spotify_data_masterpieces %>% 
     add_column(artists = "NAME")

i <- 0
#convert artist embedded data table into only first artist char
for(i in 1:length(spotify_data_masterpieces$track.artists)){
    
    # create tibble of artist and song id
    single_artist_masterpieces <- as.data.frame(spotify_data_masterpieces$track.artists[i])
    single_artist_masterpieces <- as.tibble(single_artist_masterpieces)
    
    single_artist_name_masterpieces <- single_artist_masterpieces$name

    spotify_data_masterpieces$artists[i] <- single_artist_name_masterpieces
}

spotify_data_masterpieces <- spotify_data_masterpieces %>% 
    select(-type, -uri, -track_href, -analysis_url, -track.artists) %>% 
    relocate(track.name)

```

While it appears there is little that unites the students of Columbia in their music choice, that isn't necessarily surprising. As we have explored, there are a variety of reasons for music choices and there is certainly not one correct choice. However, this seems different from the "masterpieces" of the western canon. If there truly is a canon, then it would seem reasonable that there are some consistent common threads. 


```{r echo=FALSE, message=FALSE, warning=FALSE}
multiple_masters <- spotify_data_masterpieces %>% 
  group_by(artists) %>% 
  filter(n()>1)

ggplot(
    multiple_masters, 
    aes(x = valence, y = artists)
    ) + 
  geom_density_ridges_gradient(show.legend = FALSE) +
geom_density_ridges() + 
theme_ridges() +
labs(title = "Valence across the 'masters'")

```

Interestingly, at least according to Spotify, of the great artists we studied more than 2 tracks of, it appears they are all rather gloomy and negative. Overall, their tracks are more sad and angry compared to happy. This is with the notable except of Mozart. In review, it seems to be reasonable for most of the pieces such as Beethoven's 5th or even L'Orfeo. This graph looks similar as well to the overview of the energy in various pieces. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(
    multiple_masters, 
    aes(x = energy, y = artists)
    ) + 
  geom_density_ridges_gradient(show.legend = FALSE) +
geom_density_ridges() + 
theme_ridges() +
labs(title = "Energy across the different masterpieces")

```
In this case, the statistics do a better job of showing Stravinsky as an outlier with a lot more comparitive energy. However, it is still interesting that the remaining works all score relatively low on energy. 

```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(
    multiple_masters, 
    aes(x = track.popularity, y = artists)
    ) + 
  geom_density_ridges_gradient(show.legend = FALSE) +
geom_density_ridges() + 
theme_ridges() +
labs(title = "How popular are the Western Masters?")

```

A rather ironic similarity between the "master's" that we have studied is that at least for Spotify, they are not that popular. This is a little deceptive as there are a variety of recordings for each piece, so this dilutes popularity but none-the-less, they are less popular than many in our desert-island playlist. 



```{r echo=FALSE, message=FALSE, warning=FALSE}
ggplot(
    multiple_masters, 
    aes(x = tempo, y = artists)
    ) + 
  geom_density_ridges_gradient(show.legend = FALSE) +
geom_density_ridges() + 
theme_ridges() +
labs(title = "Wide range in tempos in masterpieces")

```

Also, it is good to know that almost any tempo is sufficient for writing a masterpiece. In fact, not only any tempo, but this shows that it requires a wide range of tempos. Maybe the one unique feature would be that these master composers are just that, a master at a much larger variety of musical techniques and the combination of those is what makes their pieces flourish. Of course, the Spotify API is not yet equiped to determine that. 


Finally, the features of each song were also not indicative or predictive of other features of the song. For example, using regression, it was difficult to get any significant coefficients. Even more simple features like time seem to be independent of the others, even traits like energy or liveness.



```{r echo=FALSE, message=FALSE, warning=FALSE}

lm <- lm(data = spotify_data_masterpieces, tempo ~ danceability + energy + loudness + speechiness + acousticness + instrumentalness + liveness + valence)

summary(lm)
```


## Conclusion

In summary, there are not particularly defining features of what makes a masterpiece at least as presented through the Spotify API. Classical music and much of what we studied is slightly skewed in terms of modern analytics that look at loudness for example, but it doesn't have a very clear set of prerequisite features. This seems to fit in with our class's final discussion. Part of the greatness of the individual composers were there unique sense of expression and how they pushed the limitations of forms and styles available to them. It also shows that there is certainly more than one physical way to express yourself. 

As for our desert island playlist, it shows what we already know - Columbia students are diverse in their backgrounds and this extends to our music choices. There is no set defining characteristic that can easily identify a song that will be loved by our undergraduate. Overall, what makes a masterpiece impactful and emotive may very well be individual. 


### Coding References 

My code and project file can be found in completeness here: https://github.com/noahlove/music-hum-data


Spotify API: https://developer.spotify.com/documentation/web-api/

Spotify R Package: https://github.com/charlie86/spotifyr

Kaggle Project Example with graphs repurposed: https://www.kaggle.com/cihanoklap/top-songs-on-spotify-what-makes-them-popular